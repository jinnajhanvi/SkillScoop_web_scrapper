# -*- coding: utf-8 -*-
"""SkillScoop_web_scrapper.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wC814yL6b80p1f_oVYqxVrT1iiJ8D_hX
"""

# !pip install requests
import requests

#!pip install beautifulsoup4
from bs4 import BeautifulSoup

url = "https://www.timesjobs.com/"

response = requests.get(url)

response.status_code

response.text

soup = BeautifulSoup(response.text)

soup.find('title')

soup.find('title').text

key = "python developer"
url = f"https://www.timesjobs.com/candidate/job-search.html?searchType=personalizedSearch&from=submit&searchTextSrc=ft&searchTextText=&txtKeywords={key}&txtLocation="

response = requests.get(url)

response.status_code

soup = BeautifulSoup(response.text)

soup.find("title").text

soup.find('li', class_ = "clearfix job-bx wht-shd-bx")

jobs = soup.find_all('li', class_ = "clearfix job-bx wht-shd-bx")

len(jobs)

jobs[0]

"""## Extract company names"""

company_names = []

# Iterate through each job posting
for job in jobs:
    # Find the 'h3' tag with class 'joblist-comp-name'
    company_tag = job.find('h3', class_='joblist-comp-name')

    # Extract and clean the text
    if company_tag:
        company_name = company_tag.text.strip()  # Remove leading and trailing whitespace
        company_name = ' '.join(company_name.split())  # Normalize spaces

    company_names.append(company_name)

company_names

"""## Extracting skills"""

skills_list = []

for job in jobs:
    # Find the div containing skills
    skills_div = job.find('div', class_='srp-skills')

    if skills_div:
        # Find all visible skills (ignore ones with class "nodisplay")
        skills_tags = skills_div.find_all('span', class_=False)

        # Extract and clean skills
        skills = [skill.text.strip() for skill in skills_tags]
        skills_text = ', '.join(skills)  # Convert list to comma-separated string

    skills_list.append(skills_text)

skills_list

"""## Extracting Location"""

locations = []

for job in jobs:
    # Find the <li> tag with class 'srp-zindex location-tru' (which contains location info)
    location_tag = job.find('li', class_='srp-zindex location-tru')

    if location_tag:
        # Extract text and clean it
        location = location_tag.get_text(strip=True)  # Removes leading/trailing spaces
        location = ', '.join(location.split(','))  # Ensure proper spacing after commas

    locations.append(location)

locations

"""## Extract Experience"""

experiences = []

for job in jobs:
    # Find all <li> elements in the job post
    li_tags = job.find_all('li')

    exp_text = "N/A"  # Default if experience is not found

    for li in li_tags:
        # Check if this <li> contains the experience <i> tag
        if li.find('i', class_='srp-icons experience'):
            exp_text = li.get_text(strip=True)  # Extract text and clean it
            break  # Stop after finding the first experience tag

    experiences.append(exp_text)

experiences

"""## combined job information extractor"""

import requests
from bs4 import BeautifulSoup

def job_finder():
    key = input("Enter your skills or designation: ").strip()
    # Replace spaces with %20 for URL
    key_url = key.replace(" ", "%20")


    # Construct URL (verify these params with actual site)
    url = (
        "https://www.timesjobs.com/candidate/job-search.html?"
        "searchType=personalizedSearch&from=submit&searchTextSrc=&searchTextText="
        f"&txtKeywords={key_url}&txtLocation="
    )

    response = requests.get(url)
    soup = BeautifulSoup(response.text, "lxml")

    jobs = soup.find_all('li', class_='clearfix job-bx wht-shd-bx')

    company_names = []
    skills_list = []
    locations = []
    experiences = []
    salaries=[]
    duration=[]

    # If jobs is empty, print soup to debug
    if not jobs:
        print("No jobs found with the current selectors. Let's inspect the HTML:")
        print(soup.prettify()[:2000])
        return [{
            "Company Name": [],
            "Skills": [],
            "Location": [],
            "Experience": []
        }]

    for job in jobs:
        # COMPANY NAME
        company_tag = job.find('h3', class_='joblist-comp-name')
        if company_tag:
            comp_text = company_tag.get_text(strip=True)
            comp_text = ' '.join(comp_text.split())  # normalize spaces
        else:
            comp_text = "N/A"
        company_names.append(comp_text)

        # SKILLS
        skills_div = job.find('div', class_='srp-skills')
        if skills_div:
            # find all visible skill spans (exclude 'nodisplay' if any)
            skill_spans = skills_div.find_all('span', class_=False)
            all_skills = [sp.get_text(strip=True) for sp in skill_spans]
            skills_text = ', '.join(all_skills)
        else:
            skills_text = "N/A"
        skills_list.append(skills_text)

        # LOCATION
        loc_tag = job.find('li', class_='srp-zindex location-tru')
        if loc_tag:
            loc_text = loc_tag.get_text(strip=True)
            loc_text = ', '.join(loc_text.split(','))  # ensure spacing after commas
        else:
            loc_text = "N/A"
        locations.append(loc_text)

        # EXPERIENCE
        exp_text = "N/A"
        li_tags = job.find_all('li')
        for li in li_tags:
            if li.find('i', class_='srp-icons experience'):
                exp_text = li.get_text(strip=True)
                break
        experiences.append(exp_text)

        #salary
        salary_text = "N/A"
        li_tags = job.find_all('li')
        for li in li_tags:
            if li.find('i', class_='srp-icons salary'):
                salary_text = li.get_text(strip=True)
                break
        salaries.append(salary_text)


        # Duration
        duration_text = "N/A"
        duration_tag = job.find('span', class_='sim-posted')
        if duration_tag:
            duration_text = duration_tag.get_text(strip=True)
        duration.append(duration_text)


    result = {
        "Company Name": company_names,
        "Skills": skills_list,
        "Location": locations,
        "Experience": experiences,
        "Salary": salaries,
        "Duration": duration
    }

    print(f"Extracted {len(company_names)} job postings.")
    return result

data=job_finder()

data

import pandas as pd

df = pd.DataFrame(data)

df.head()

df.to_csv("python_developer_jobs.csv")